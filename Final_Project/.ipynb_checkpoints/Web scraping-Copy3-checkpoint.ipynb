{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project - Movies recommendation\n",
    "\n",
    "In the final project, we will scrape the text of hollywood movies released since 2000, and build a recommender system based on the textual content of the movies obtained from Wikipedia.\n",
    "\n",
    "## Phase 1: Gathering data\n",
    "\n",
    "The wikipedia URLs have the common URL format given below (where XXXX in the below URL format represents the year):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/List_of_American_films_of_XXXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "import time\n",
    "import pickle #To save the objects that were created using webscraping\n",
    "import pprint\n",
    "from lxml import html\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import urllib\n",
    "import os\n",
    "#import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Step-1 \n",
    "Get the URL of each of the movie released since 2000 year from Wikipedia. The following code blocks will get the URLs along with othre details like cast, director, genre and year. The detailes are obtained in 2 pahses. In first phase we get the Movie names, URL and other details for the movies released between 2000 - 2013 years. In the second phase we get the movies details for the years 2014 to 2016. Since the format of the web page is different, we have to do this in 2 phases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Get the movies and URLs for the years 2000-2014\n",
    "URL = list()\n",
    "Movie_Name = list()\n",
    "Director = list()\n",
    "Cast = list()\n",
    "Genre = list()\n",
    "year = list()\n",
    "\n",
    "bs = BeautifulSoup(html)\n",
    "for y in list(range(2000,2014)):\n",
    "    url = \"https://en.wikipedia.org/wiki/List_of_American_films_of_\"+str(y)\n",
    "    html = urlopen(url)\n",
    "    time.sleep(3)\n",
    "    bs = BeautifulSoup(html)\n",
    "    for table in bs.find_all('table', {\"class\":\"wikitable\"}):\n",
    "        for row in table.find_all('tr'):\n",
    "            columns = row.find_all('td')\n",
    "            if len(columns) > 4:\n",
    "                Movie_Name.append(columns[0].get_text())\n",
    "                Director.append(columns[1].get_text())\n",
    "                Cast.append(columns[2].get_text())\n",
    "                Genre.append(columns[3].get_text())\n",
    "                year.append(y)\n",
    "                try:\n",
    "                    a = columns[0].find('a',href=True)['href']\n",
    "                    URL.append(\"https://en.wikipedia.org\"+a)\n",
    "                except:\n",
    "                    URL.append(\"NA\")\n",
    "                    continue\n",
    "\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Get the movies details for the years 2014 to 2016\n",
    "URL1 = list()\n",
    "Movie_Name1 = list()\n",
    "Director1 = list()\n",
    "Cast1 = list()\n",
    "Genre1 = list()\n",
    "year1 = list()\n",
    "\n",
    "for y in range(2014,2017):                    \n",
    "    url = \"https://en.wikipedia.org/wiki/List_of_American_films_of_\"+str(y)\n",
    "    try: \n",
    "        html = urlopen(url)\n",
    "    except:\n",
    "        print(\"problem with the following URL...continuining...:\")\n",
    "        print(url)\n",
    "        continue\n",
    "    time.sleep(3)\n",
    "    bs = BeautifulSoup(html)\n",
    "    for table in bs.find_all('table', {\"class\":\"wikitable\"}):\n",
    "        for row in table.find_all('tr'):\n",
    "            columns = row.find_all('td')\n",
    "            if len(columns) > 3: #To make sure that we are accessing the movies tables only\n",
    "                if len(columns) == 6:\n",
    "                    #print(columns[0].get_text())\n",
    "                    Movie_Name1.append(columns[0].get_text())\n",
    "                    Director1.append(columns[1].get_text())\n",
    "                    Cast1.append(columns[2].get_text())\n",
    "                    Genre1.append(columns[3].get_text())\n",
    "                    year1.append(y)\n",
    "                    try:\n",
    "                        a=columns[0].find('a',href=True)['href']\n",
    "                        URL1.append(\"https://en.wikipedia.org\"+a)\n",
    "                    except:\n",
    "                        URL1.append(\"NA\")\n",
    "                        continue\n",
    "                \n",
    "                if len(columns) == 7:\n",
    "                    #print(columns[1].get_text())\n",
    "                    Movie_Name1.append(columns[1].get_text())\n",
    "                    Director1.append(columns[2].get_text())\n",
    "                    Cast1.append(columns[3].get_text())\n",
    "                    Genre1.append(columns[4].get_text())\n",
    "                    year1.append(y)\n",
    "                    \n",
    "                    try:\n",
    "                        a=columns[1].find('a',href=True)['href']\n",
    "                        URL1.append(\"https://en.wikipedia.org\"+a)\n",
    "                    except:\n",
    "                        URL1.append(\"NA\")\n",
    "                        continue\n",
    "\n",
    "                if len(columns) > 7:\n",
    "                    #print(\"col len:{}\".format(len(columns)))\n",
    "                    #print(columns[2].get_text())\n",
    "                    Movie_Name1.append(columns[2].get_text())\n",
    "                    Director1.append(columns[3].get_text())\n",
    "                    Cast1.append(columns[4].get_text())\n",
    "                    Genre1.append(columns[5].get_text())\n",
    "                    year1.append(y)                    \n",
    "                    try:\n",
    "                        a=columns[2].find('a',href=True)['href']\n",
    "                        URL1.append(\"https://en.wikipedia.org\"+a)\n",
    "                    except:\n",
    "                        URL1.append(\"NA\")\n",
    "                        continue\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the results\n",
    "We will save the movies details as a CSV file named URL.csv. This helps us to avoid running step-1 again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to coerce to Series, length must be 7: given 487",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-5bddeed75828>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMovie_Name\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mMovie_Name1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mURL\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mURL1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0myear1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDirector\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mDirector1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mCast\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mCast1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mGenre\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mGenre1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m                  \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Movie\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"URL\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Year\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Director\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Cast\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Genre\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#Remove the rows which do not have URL information\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sekhar\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mf\u001b[1;34m(self, other, axis, level, fill_value)\u001b[0m\n\u001b[0;32m   1229\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefault_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1231\u001b[1;33m         \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_align_method_FRAME\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1233\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Another DataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sekhar\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36m_align_method_FRAME\u001b[1;34m(left, right, axis)\u001b[0m\n\u001b[0;32m   1147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1148\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1149\u001b[1;33m         \u001b[0mright\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_series\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# skips np scalar\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sekhar\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mto_series\u001b[1;34m(right)\u001b[0m\n\u001b[0;32m   1142\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1144\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1145\u001b[0m             \u001b[0mright\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to coerce to Series, length must be 7: given 487"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.DataFrame(list(zip(Movie_Name+Movie_Name1,URL+URL1,year+year1,Director+Director1,Cast+Cast1,Genre+Genre1)),\\\n",
    "                  columns=[\"Movie\",\"URL\",\"Year\",\"Director\",\"Cast\",\"Genre\"])\n",
    "\n",
    "#Remove the rows which do not have URL information\n",
    "\n",
    "df = df[df[\"URL\"] != \"NA\"]\n",
    "#df[\"Movie_ID\"] = range(1,df.shape[0]+1)\n",
    "#Write the file\n",
    "df.to_csv(\"URL.csv\",encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Added later...\n",
    "URL = pd.read_csv(\"URL.csv\")\n",
    "cols = URL.columns\n",
    "URL[\"Movie_ID\"] = URL.index + 1\n",
    "\n",
    "#print(cols)\n",
    "display(URL.head())\n",
    "display(URL.tail())\n",
    "URL.to_csv(\"Movies_URL_Latest.csv\",encoding='utf-8',index=False)\n",
    "URL.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4045"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Movie_ID\"].max()\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the saved file to a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie</th>\n",
       "      <th>URL</th>\n",
       "      <th>Year</th>\n",
       "      <th>Director</th>\n",
       "      <th>Cast</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Movie_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102 Dalmatians</td>\n",
       "      <td>https://en.wikipedia.org/wiki/102_Dalmatians</td>\n",
       "      <td>2000</td>\n",
       "      <td>Kevin Lima</td>\n",
       "      <td>Glenn Close, Gérard Depardieu, Alice Evans</td>\n",
       "      <td>Comedy, family</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28 Days</td>\n",
       "      <td>https://en.wikipedia.org/wiki/28_Days_(film)</td>\n",
       "      <td>2000</td>\n",
       "      <td>Betty Thomas</td>\n",
       "      <td>Sandra Bullock, Viggo Mortensen</td>\n",
       "      <td>Drama</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3 Strikes</td>\n",
       "      <td>https://en.wikipedia.org/wiki/3_Strikes_(film)</td>\n",
       "      <td>2000</td>\n",
       "      <td>DJ Pooh</td>\n",
       "      <td>Brian Hooks, N'Bushe Wright</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The 6th Day</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_6th_Day</td>\n",
       "      <td>2000</td>\n",
       "      <td>Roger Spottiswoode</td>\n",
       "      <td>Arnold Schwarzenegger, Robert Duvall</td>\n",
       "      <td>Science fiction</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Across the Line</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Across_the_Line_...</td>\n",
       "      <td>2000</td>\n",
       "      <td>Martin Spottl</td>\n",
       "      <td>Brad Johnson, Adrienne Barbeau, Brian Bloom</td>\n",
       "      <td>Thriller</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Movie                                                URL  Year  \\\n",
       "0    102 Dalmatians       https://en.wikipedia.org/wiki/102_Dalmatians  2000   \n",
       "1           28 Days       https://en.wikipedia.org/wiki/28_Days_(film)  2000   \n",
       "2         3 Strikes     https://en.wikipedia.org/wiki/3_Strikes_(film)  2000   \n",
       "3       The 6th Day          https://en.wikipedia.org/wiki/The_6th_Day  2000   \n",
       "4   Across the Line  https://en.wikipedia.org/wiki/Across_the_Line_...  2000   \n",
       "\n",
       "             Director                                         Cast  \\\n",
       "0          Kevin Lima   Glenn Close, Gérard Depardieu, Alice Evans   \n",
       "1        Betty Thomas              Sandra Bullock, Viggo Mortensen   \n",
       "2             DJ Pooh                  Brian Hooks, N'Bushe Wright   \n",
       "3  Roger Spottiswoode         Arnold Schwarzenegger, Robert Duvall   \n",
       "4       Martin Spottl  Brad Johnson, Adrienne Barbeau, Brian Bloom   \n",
       "\n",
       "             Genre  Movie_ID  \n",
       "0   Comedy, family         1  \n",
       "1            Drama         2  \n",
       "2           Comedy         3  \n",
       "3  Science fiction         4  \n",
       "4         Thriller         5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie</th>\n",
       "      <th>URL</th>\n",
       "      <th>Year</th>\n",
       "      <th>Director</th>\n",
       "      <th>Cast</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Movie_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4040</th>\n",
       "      <td>Inferno</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Inferno_(2016_film)</td>\n",
       "      <td>2016</td>\n",
       "      <td>Ron Howard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4041</th>\n",
       "      <td>Friend Request</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Friend_Request</td>\n",
       "      <td>2016</td>\n",
       "      <td>Simon Verhoeven</td>\n",
       "      <td>Alycia Debnam-Carey</td>\n",
       "      <td>Horror</td>\n",
       "      <td>4042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4042</th>\n",
       "      <td>Rogue One: A Star Wars Story (film)</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Rogue_One</td>\n",
       "      <td>2016</td>\n",
       "      <td>Felicity Jones</td>\n",
       "      <td>Diego Luna</td>\n",
       "      <td>Sci-Fi</td>\n",
       "      <td>4043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4043</th>\n",
       "      <td>The Founder</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Founder_(film)</td>\n",
       "      <td>2016</td>\n",
       "      <td>John Lee Hancock</td>\n",
       "      <td>Michael Keaton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4044</th>\n",
       "      <td>Rings</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Rings_(2016_film)</td>\n",
       "      <td>2016</td>\n",
       "      <td>F. Javier Gutiérrez</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Movie  \\\n",
       "4040                              Inferno   \n",
       "4041                       Friend Request   \n",
       "4042  Rogue One: A Star Wars Story (film)   \n",
       "4043                          The Founder   \n",
       "4044                                Rings   \n",
       "\n",
       "                                                    URL  Year  \\\n",
       "4040  https://en.wikipedia.org/wiki/Inferno_(2016_film)  2016   \n",
       "4041       https://en.wikipedia.org/wiki/Friend_Request  2016   \n",
       "4042            https://en.wikipedia.org/wiki/Rogue_One  2016   \n",
       "4043   https://en.wikipedia.org/wiki/The_Founder_(film)  2016   \n",
       "4044    https://en.wikipedia.org/wiki/Rings_(2016_film)  2016   \n",
       "\n",
       "                 Director                 Cast   Genre  Movie_ID  \n",
       "4040           Ron Howard                  NaN     NaN      4041  \n",
       "4041      Simon Verhoeven  Alycia Debnam-Carey  Horror      4042  \n",
       "4042       Felicity Jones           Diego Luna  Sci-Fi      4043  \n",
       "4043     John Lee Hancock       Michael Keaton     NaN      4044  \n",
       "4044  F. Javier Gutiérrez                  NaN     NaN      4045  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4045, 7)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL = pd.read_csv(\"URL.csv\")\n",
    "\n",
    "display(URL.head())\n",
    "display(URL.tail())\n",
    "\n",
    "URL.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "There are 4045 movies that have to be scraped from Wikipedia. Let us do this as batches. Our goal is to scrape the image of the movie (if exists), along with the plot and initial introduction texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "We will code the following functions to obtain the plot information of the movie, along with the release poster image of the movie.\n",
    "\n",
    "**Open_URL(url)** Gets the HTML content, prepares Beautiful Soup object and returns the Beautiful Soup object. The _url_ parameter represents the complete URL of the webpage.\n",
    "\n",
    "**Get_Text(bs,file)** Gets the plot of the movie. In case plot is not present, gets the text data of all the HTML Paragraphs of the input Beautiful Soup object (the _bs_) parameter. The _file_ parameter contains the desired file name, which will be the name of the file that contains the movie's plot. Returns -1 or 0 or 1. If -1, a severe error has occurred, and NO text was saved, 0 represents a successful parsing of the plot's text (and the website contains Plot HTML ID), and 1 represents a successful parsion of the complete text (since the web page does NOT have Plot ID).\n",
    "\n",
    "**Get_Poster(bs, file)** Gets the release poster of the movie and saves the file. Returns 0 if successful else returns -1.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Open_URL(url):\n",
    "    '''\n",
    "    Gets the HTML content, prepares Beautiful Soup object and \n",
    "    returns the \n",
    "    Beautiful Soup object. \n",
    "    The url parameter represents the complete URL of the webpage.\n",
    "    '''\n",
    "    try:\n",
    "         html = urlopen(url)\n",
    "    except:\n",
    "        return -1\n",
    "    try:\n",
    "        #bs = BeautifulSoup(html).encode(\"ascii\")\n",
    "        bs = BeautifulSoup(html)\n",
    "        \n",
    "        return bs\n",
    "    except:\n",
    "        return -2       \n",
    "\n",
    "def Get_Plot(bs):    \n",
    "    try:\n",
    "        p = bs.find(\"p\")\n",
    "        initial_paragraph = p.getText()\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "    # collect plot in this list\n",
    "    plot = []\n",
    "    \n",
    "    # find the node with id of \"Plot\"\n",
    "    try:\n",
    "        mark = bs.find(id=\"Plot\")\n",
    "        # walk through the siblings of the parent (H2) node \n",
    "        # until we reach the next H2 node\n",
    "        for elt in mark.parent.nextSiblingGenerator():\n",
    "            if elt.name == \"h2\":\n",
    "                break\n",
    "            if hasattr(elt, \"text\"):\n",
    "                plot.append(elt.text)\n",
    "    except:\n",
    "         return -2\n",
    "    \n",
    "    try:\n",
    "        plot=\"\".join(plot)\n",
    "        text = initial_paragraph + plot\n",
    "        return text\n",
    "    except:\n",
    "        return -3    \n",
    "    \n",
    "\n",
    "    \n",
    "def Get_All_Text(bs):\n",
    "    try:\n",
    "        p = bs.find_all(\"p\")\n",
    "        l = list()\n",
    "        for i in p:\n",
    "            l.append(i.getText())\n",
    "        return \" \".join(l)\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "def Save_Text_File(text,text_file_name):\n",
    "    try:\n",
    "        os.chdir(\"./data\")\n",
    "    except:\n",
    "        return -1\n",
    "    \n",
    "    with open(text_file_name, 'w',encoding='utf-8') as f:\n",
    "         f.write(text)\n",
    "    \n",
    "    try:\n",
    "        os.chdir(\"..\")\n",
    "        return 0\n",
    "    except:\n",
    "        return -2\n",
    "\n",
    "def Get_And_Save_Image(bs,image_file_name):    \n",
    "    try: \n",
    "        img=bs.findAll(\"img\",{\"class\":\"thumbborder\"})\n",
    "        img_URL=\"https:\"+img[0]['src']\n",
    "    except:\n",
    "        return -1\n",
    "     \n",
    "    try:\n",
    "        os.chdir(\"./images\")\n",
    "        ignore=urllib.request.urlretrieve(img_URL,image_file_name)\n",
    "        os.chdir(\"..\")\n",
    "        return 0\n",
    "    except:\n",
    "        return -2\n",
    "\n",
    "def Write_Error(url,msg,file):\n",
    "    with open(file,'a') as f:\n",
    "        f.write(\"\\n\"+msg)\n",
    "        f.write(\"\\n\"+url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning the files download...\n",
      "Processed 100 URLs\n",
      "Elapsed time to process 100 URLs:446.38204622268677 secs\n",
      "Processed 200 URLs\n",
      "Elapsed time to process 100 URLs:433.5029966831207 secs\n",
      "Processed 300 URLs\n",
      "Elapsed time to process 100 URLs:461.3205850124359 secs\n",
      "Processed 400 URLs\n",
      "Elapsed time to process 100 URLs:458.53809428215027 secs\n",
      "Processed 500 URLs\n",
      "Elapsed time to process 100 URLs:476.4255542755127 secs\n",
      "Processed 600 URLs\n",
      "Elapsed time to process 100 URLs:473.6112816333771 secs\n",
      "Processed 700 URLs\n",
      "Elapsed time to process 100 URLs:458.1378722190857 secs\n",
      "Processed 800 URLs\n",
      "Elapsed time to process 100 URLs:434.91878509521484 secs\n",
      "Processed 900 URLs\n",
      "Elapsed time to process 100 URLs:569.373973608017 secs\n",
      "Processed 1000 URLs\n",
      "Elapsed time to process 100 URLs:533.2878279685974 secs\n",
      "Processed 1100 URLs\n",
      "Elapsed time to process 100 URLs:493.94636368751526 secs\n",
      "Processed 1200 URLs\n",
      "Elapsed time to process 100 URLs:560.7728536128998 secs\n",
      "Processed 1300 URLs\n",
      "Elapsed time to process 100 URLs:519.7430667877197 secs\n",
      "Processed 1400 URLs\n",
      "Elapsed time to process 100 URLs:661.1075065135956 secs\n",
      "Processed 1500 URLs\n",
      "Elapsed time to process 100 URLs:468.4266812801361 secs\n",
      "Processed 1600 URLs\n",
      "Elapsed time to process 100 URLs:482.55657744407654 secs\n",
      "Processed 1700 URLs\n",
      "Elapsed time to process 100 URLs:468.59105467796326 secs\n",
      "Processed 1800 URLs\n",
      "Elapsed time to process 100 URLs:448.06637740135193 secs\n",
      "Processed 1900 URLs\n",
      "Elapsed time to process 100 URLs:454.26227259635925 secs\n",
      "Processed 2000 URLs\n",
      "Elapsed time to process 100 URLs:437.51902770996094 secs\n",
      "Processed 2100 URLs\n",
      "Elapsed time to process 100 URLs:437.7170066833496 secs\n",
      "Processed 2200 URLs\n",
      "Elapsed time to process 100 URLs:432.09807682037354 secs\n",
      "Processed 2300 URLs\n",
      "Elapsed time to process 100 URLs:429.547082901001 secs\n",
      "Processed 2400 URLs\n",
      "Elapsed time to process 100 URLs:431.0166103839874 secs\n",
      "Processed 2500 URLs\n",
      "Elapsed time to process 100 URLs:426.8530662059784 secs\n",
      "Processed 2600 URLs\n",
      "Elapsed time to process 100 URLs:434.2797124385834 secs\n",
      "Processed 2700 URLs\n",
      "Elapsed time to process 100 URLs:432.32950735092163 secs\n",
      "Processed 2800 URLs\n",
      "Elapsed time to process 100 URLs:462.65187335014343 secs\n",
      "Processed 2900 URLs\n",
      "Elapsed time to process 100 URLs:475.1674907207489 secs\n",
      "Processed 3000 URLs\n",
      "Elapsed time to process 100 URLs:446.28495264053345 secs\n",
      "Processed 3100 URLs\n",
      "Elapsed time to process 100 URLs:486.55276560783386 secs\n",
      "Processed 3200 URLs\n",
      "Elapsed time to process 100 URLs:478.56283259391785 secs\n",
      "Processed 3300 URLs\n",
      "Elapsed time to process 100 URLs:509.5021858215332 secs\n",
      "Processed 3400 URLs\n",
      "Elapsed time to process 100 URLs:468.18198013305664 secs\n",
      "Processed 3500 URLs\n",
      "Elapsed time to process 100 URLs:441.2250940799713 secs\n",
      "Processed 3600 URLs\n",
      "Elapsed time to process 100 URLs:445.52249574661255 secs\n",
      "Processed 3700 URLs\n",
      "Elapsed time to process 100 URLs:511.63219952583313 secs\n"
     ]
    }
   ],
   "source": [
    "tracker = 0\n",
    "term=1\n",
    "start = time.time() # Get start time\n",
    "print(\"Beginning the files download...\")\n",
    "#k = 1\n",
    "for movie, url, year,Movie_ID in zip(list(URL[\"Movie\"]),list(URL[\"URL\"]),list(URL[\"Year\"]),list(URL[\"Movie_ID\"])):\n",
    "    #if k < 30:\n",
    "    #    k = k+1\n",
    "    #    continue\n",
    "    #print(\"{},{},{}\".format(movie,url,year))\n",
    "    #Open the URL\n",
    "    \n",
    "    bs=Open_URL(url)\n",
    "\n",
    "    if bs == -1:\n",
    "        Write_Error(url,\"Error in opening the URL\",\"error.txt\")\n",
    "        #print(\"Error in opening the URL: {}\".format(url))\n",
    "        continue\n",
    "        \n",
    "\n",
    "    if bs == -2:\n",
    "        Write_Error(url,\"Error in the creation of bs object for the URL\",\"error.txt\")\n",
    "        #print(\"Error in the creation of bs object for the URL: {}\".format(url))\n",
    "        continue\n",
    "\n",
    "    time.sleep(3)\n",
    "\n",
    "    #create a name for the files\n",
    "    #image_file_name = str(year)+\"_\"+movie.strip()+\".jpg\"\n",
    "    #text_file_name =  str(year)+\"_\"+movie.strip()+\".txt\"\n",
    "    image_file_name = str(Movie_ID)+\".jpg\"\n",
    "    text_file_name =  str(Movie_ID)+\".txt\"\n",
    "\n",
    "    text=Get_Plot(bs)\n",
    "    \n",
    "    if text == -1:\n",
    "        Write_Error(url,\"No paragraphs are found\",\"error.txt\")\n",
    "        #print(\"No paragraphs are found\")\n",
    "        #print(url)\n",
    "        continue\n",
    "\n",
    "    if text == -2:\n",
    "        Write_Error(url,\"Warning: No Plot ID found\",\"error.txt\")\n",
    "        #print(\"Warning: No Plot ID found\")\n",
    "        #print(url)\n",
    "        \n",
    "        text = Get_All_Text(bs)\n",
    "        if text == -1:\n",
    "            Write_Error(url,\"No paragraphs are found\",\"error.txt\")\n",
    "            #print(\"No paragraphs are found\")\n",
    "            #print(url)\n",
    "            continue\n",
    "        \n",
    "    if text == -3:\n",
    "        Write_Error(url,\"Error while appending the main plot with the initial paragraph\",\"error.txt\")\n",
    "        #print(\"Error while appending the main plot with the initial paragraph\")\n",
    "        #print(url)\n",
    "        continue\n",
    "    \n",
    "    status = Save_Text_File(text,text_file_name)\n",
    "    \n",
    "    if status == -1:\n",
    "        Write_Error(url,\"Not able to change the directory to ./data\",\"error.txt\")\n",
    "        #print(\"Not able to change the directory to ./data\")\n",
    "        #print(url)\n",
    "        continue\n",
    "    \n",
    "    if status == -2:\n",
    "        Write_Error(url,\"Not able to change the directory to .. (parent directory) from ./data\",\"error.txt\")\n",
    "        #print(\"Not able to change the directory to .. (parent directory) from ./data\")\n",
    "        #print(url)\n",
    "        continue\n",
    "        \n",
    "    #Downloading Image files    \n",
    "    status = Get_And_Save_Image(bs,image_file_name)\n",
    "    \n",
    "    if status == -1:\n",
    "        Write_Error(url,\"Not able to find the image\",\"error.txt\")\n",
    "        #print(\"Not able to find the image\")\n",
    "        #print(url)\n",
    "        continue\n",
    "\n",
    "    if status == -2:\n",
    "        Write_Error(url,\"Not able to save the image\",\"error.txt\")\n",
    "        #print(\"Not able to save the image\")\n",
    "        #print(url)\n",
    "        continue\n",
    "\n",
    "    #Check the status of the webbot    \n",
    "    tracker = tracker + 1\n",
    "    if (tracker % 100 == 0):\n",
    "        print(\"Processed {} URLs\".format(tracker))\n",
    "        end = time.time() # Get end time\n",
    "        elapsed_time = end - start\n",
    "        print(\"Elapsed time to process 100 URLs:{} secs\".format(elapsed_time))\n",
    "        start = time.time() # Get end time\n",
    "        #break\n",
    "\n",
    "    #if term == 1:\n",
    "    #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://en.wikipedia.org/wiki/Brother_(2000_film)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get all text from the URL\n",
    "getAllText(bs):\n",
    "    try:\n",
    "        p = bs.find_all(\"p\")\n",
    "        for i in p:\n",
    "             print(i.getText())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000_102 Dalmatians.jpg\n",
      "Error in extracting plot\n",
      "https://en.wikipedia.org/wiki/102_Dalmatians\n",
      "2000_28 Days.jpg\n",
      "2000_3 Strikes.jpg\n",
      "Error in extracting plot\n",
      "https://en.wikipedia.org/wiki/3_Strikes_(film)\n",
      "2000_The 6th Day.jpg\n",
      "Error in extracting plot\n",
      "https://en.wikipedia.org/wiki/The_6th_Day\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-35a094a2d6ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[1;31m#Create a beautiful soup object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tracker = 0\n",
    "term=1\n",
    "start = time.time() # Get start time\n",
    "\n",
    "for movie, url, year in zip(list(URL[\"Movie\"]),list(URL[\"URL\"]),list(URL[\"Year\"])):\n",
    "    #print(\"{},{},{}\".format(movie,url,year))\n",
    "    #Open the URL\n",
    "    \n",
    "    try:\n",
    "        html = urlopen(url)\n",
    "    except:\n",
    "        print(\"Not able to connect to the following URL:\")\n",
    "        print(url)\n",
    "        continue\n",
    "        \n",
    "    time.sleep(3)\n",
    "    #Create a beautiful soup object\n",
    "    try:\n",
    "        bs = BeautifulSoup(html)\n",
    "    except:\n",
    "        print(\"Error in the creation of beautifulsoup object\")\n",
    "        print(url)\n",
    "        continue\n",
    "\n",
    "    #create a name for the files\n",
    "    image_file_name = str(year)+\"_\"+movie.strip()+\".jpg\"\n",
    "    text_file_name =  str(year)+\"_\"+movie.strip()+\".txt\"\n",
    "    #print(image_file_name)\n",
    "    #Get the text (initial paragraph first):\n",
    "    try:\n",
    "        p = bs.find(\"p\")\n",
    "        initial_paragraph = p.getText()\n",
    "    except:\n",
    "        print(\"Error in getting the first paragraph\")\n",
    "        print(url)\n",
    "        continue\n",
    "    \n",
    "    # collect plot in this list\n",
    "    plot = []\n",
    "    \n",
    "    # find the node with id of \"Plot\"\n",
    "    try:\n",
    "        mark = bs.find(id=\"Plot\")\n",
    "    except:\n",
    "        print(\"Error in getting plot marker\")\n",
    "        print(url)\n",
    "        continue\n",
    "\n",
    "    # walk through the siblings of the parent (H2) node \n",
    "    # until we reach the next H2 node\n",
    "    try:\n",
    "        for elt in mark.parent.nextSiblingGenerator():\n",
    "            if elt.name == \"h2\":\n",
    "                break\n",
    "            if hasattr(elt, \"text\"):\n",
    "                plot.append(elt.text)\n",
    "    except:\n",
    "        print(\"Error in extracting plot\")\n",
    "        print(url)\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        plot=\"\".join(plot)\n",
    "        text = initial_paragraph + plot\n",
    "    except:\n",
    "        print(\"Error in the joining of text\")\n",
    "        print(url)\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        os.chdir(\"./data\")\n",
    "    except:\n",
    "        print(\"Error while changing the directory to data\")\n",
    "        print(url)\n",
    "        continue\n",
    "    \n",
    "    with open(text_file_name, 'w') as f:\n",
    "        f.write(text)\n",
    "    \n",
    "    try:\n",
    "        os.chdir(\"..\")\n",
    "    except:\n",
    "        print(\"Error while changing the directory after saving data\")\n",
    "        print(url)\n",
    "        continue\n",
    "\n",
    "    \n",
    "    \n",
    "    #Downloading Image files\n",
    "    try: \n",
    "        img=bs.findAll(\"img\",{\"class\":\"thumbborder\"})\n",
    "        img_URL=\"https:\"+img[0]['src']\n",
    "    except:\n",
    "        print(\"Error while processing the image file\")\n",
    "        print(img_URL)\n",
    "        print(url)\n",
    "    \n",
    "    try:\n",
    "        os.chdir(\"./images\")\n",
    "        #ignore = urllib.request.urlretrieve(img_URL,os.path.basename(image_file_name))\n",
    "        #urllib.request.urlretrieve(img_URL,os.path.basename(image_file_name))\n",
    "        ignore=urllib.request.urlretrieve(img_URL,image_file_name)\n",
    "    except:\n",
    "        print(\"Error while changing the directory, to save image file\")\n",
    "        print(img_URL)\n",
    "        print(url)\n",
    "        \n",
    "    try:       \n",
    "        os.chdir(\"..\")\n",
    "    except:\n",
    "        print(\"Error while changing the directory, after saving the image file\")\n",
    "        print(img_URL)\n",
    "        print(url)\n",
    "        \n",
    "    tracker = tracker + 1\n",
    "    if (tracker % 10 == 0):\n",
    "        print(\"Processed {} URLs\".format(tracker))\n",
    "        end = time.time() # Get end time\n",
    "        elapsed_time = end - start\n",
    "        print(\"Elapsed time to process 100 URLs:{} secs\".format(elapsed_time))\n",
    "        start = time.time() # Get end time\n",
    "        break\n",
    "\n",
    "    #if term == 1:\n",
    "    #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url='https://en.wikipedia.org/wiki/102_Dalmatians'\n",
    "html = urlopen(url)\n",
    "bs = BeautifulSoup(html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102 Dalmatians is a 2000 American family comedy film directed by Kevin Lima in his live-action directorial debut and produced by Edward S. Feldman and Walt Disney Pictures. It is the sequel to the 1996 film 101 Dalmatians and stars Glenn Close reprising her role as Cruella de Vil as she attempts to steal puppies for her \"grandest\" fur coat yet. Close and Tim McInnerny were the only two actors from the first film to return for the sequel, however. The film was nominated for an Academy Award for Best Costume Design, but lost to Gladiator.[2]   After three years in prison, Cruella de Vil has been cured of her desire for fur coats by Dr. Pavlov and is released into the custody of the probation office on the provision that she will be forced to pay the remainder of her fortune (eight million pounds) to all the dog shelters in the borough of Westminster should she repeat her crime. Cruella therefore mends her working relationship with her valet Alonzo and has him lock away all her fur coats. Cruella's probation officer, Chloe Simon, nevertheless suspects her, partly because Chloe is the owner of the now-adult Dipstick (one of the original 15 puppies from the previous film). Dipstick's mate, Dottie, has recently given birth to three puppies: Domino, Little Dipper and Oddball (who lacks spots). To mend her reputation, Cruella buys the Second Chance Dog shelter, owned by Kevin Shepherd, to resolve its financial insolvency that is on the verge of eviction. Meanwhile, Dr. Pavlov discovers that when his therapy's subjects are subjected to loud noises, they revert to their original states but conceals this discovery. When Big Ben rings in her presence, Cruella reverts to her former personality and enlists the help of French furrier Jean-Pierre LePelt to steal 102 Dalmatian puppies for a new fur coat. When Kevin tells Chloe that if Cruella violates her parole, her entire fortune will go to him, since his dog shelter is the only one in the borough of Westminster, Cruella has Kevin framed for the theft of the puppies and invites Chloe to dinner while LePelt steals Dottie and her three puppies. Dipstick hurries back to the apartment and hides in LePelt's truck but is later captured at the train station. Chloe rushes home to save her pets but arrives too late. She is joined by Kevin, who has escaped from prison with help from his dogs and talking parrot, Waddlesworth. Upon finding a ticket for the Orient Express to Paris dropped by LePelt, Kevin and Chloe attempt and fail to stop Cruella and LePelt, but Oddball and Waddlesworth pursue their enemies secretly. In Paris, Kevin and Chloe save some of the captive puppies, but they are seen and locked in the cellar just as the puppies flee. Cruella goes after the puppies alone. Alonzo, when scolded beyond his patience and had enough of being abused, defeats LePelt and frees Kevin and Chloe and they give chase to a wedding cake factory, where the puppies and Kevin's dogs imprison Cruella in an immense cake. She and LePelt are thereupon arrested. Kevin and Chloe are personally awarded the remnants of Cruella's fortune by Alonzo himself and Oddball's coat develops spots. The early working title was 101 Dalmatians Returns. Production began in December 1998 and ended in mid-November 1999. The film was set to be released on June 30, 2000, but was pushed back to November 22, 2000. Oxford Prison was used for the scene as Cruella walked out of prison. 102 Dalmatians was filmed partially in Paris. On November 6, 1999, Disney released the soundtrack to the movie, including pre-eminently, a cover of Paul Anka's \"Puppy Love\" (sung by Myra)[3] and original songs: Mike Himelstein's \"What Can a Bird Do?\" (voiced by Jeff Bennett), \"My Spot in the World\" (sung by Lauren Christy) and \"Cruella De Vil 2000\" (better known as \"Cruella De Vil (102 Dalmatians),\" sung by Camara Kambon and Mark Campbell[4] of Jack Mack and the Heart Attack[citation needed] – a derivation of \"Cruella de Vil\").[5] The film opened at the third position behind M. Night Shyamalan's Unbreakable and Ron Howard's How the Grinch Stole Christmas. The film did well at the box office, earning $66,957,026 in the U.S. and $116,654,745 overseas, bringing its total to $183,611,771 worldwide.[1] After premiering in New Zealand, the film received positive reviews and was described by media as a \"howling success\".[6] In America, the film received generally negative reviews from critics. On Rotten Tomatoes, the film has a 31% \"Rotten\" rating, based on 90 reviews, with the site's consensus reading \"This sequel to the live-action 101 Dalmatians is simply more of the same. Critics say it also drags in parts-- potentially boring children-- and that it's too violent for a G-rated movie.\"[7] On the similar review site Metacritic, the film has a score of 35/100, based on 24 critics.[8] 102 Dalmatians was released on VHS and DVD on April 3, 2001 and re-released on September 16, 2008. A video game based on the film, that was entitled 102 Dalmatians: Puppies to the Rescue, was released in 2000, with Frankie Muniz as the voice of Domino, Molly Marlette as the voice of Oddball and Susanne Blakeslee as the voice of Cruella de Vil. Horace and Jasper also appeared in the game despite not being present in the film.[9]\n"
     ]
    }
   ],
   "source": [
    "p = bs.find_all(\"p\")\n",
    "l = list()\n",
    "for i in p:\n",
    "    l.append(i.getText())\n",
    "    #print(i.getText())\n",
    "print(\" \".join(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rings is a 2017 American supernatural psychological horror film directed by F. Javier Gutiérrez, written by David Loucka, Jacob Aaron Estes and Akiva Goldsman and starring Matilda Lutz, Alex Roe, Johnny Galecki, Vincent D'Onofrio, Aimee Teegarden and Bonnie Morgan. It is the third film in The Ring series and takes place thirteen years after The Ring (2002).\n"
     ]
    }
   ],
   "source": [
    "p = bs.find(\"p\")\n",
    "initial_paragraph = p.getText()\n",
    "print(initial_paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rings is a 2017 American supernatural psychological horror film directed by F. Javier Gutiérrez, written by David Loucka, Jacob Aaron Estes and Akiva Goldsman and starring Matilda Lutz, Alex Roe, Johnny Galecki, Vincent D\\'Onofrio, Aimee Teegarden and Bonnie Morgan. It is the third film in The Ring series and takes place thirteen years after The Ring (2002).In 2013, on an airplane bound for Seattle, passenger Carter reveals to Faith that he has watched Samara Morgan’s cursed videotape. Faith tells another passenger Kelly, who reveals she has seen the tape too. She asks Carter if he made a copy and after learning he hasn\\'t, the airplane begins to malfunction as Samara comes for Carter and eventually causes the plane to crash.Two years later, in 2015, college professor Gabriel buys an old VCR once owned by Carter, discovering the videotape inside. Elsewhere, Julia sees her boyfriend Holt off to college, but becomes concerned when he falls out of contact. She is inspired to find him when a panicked girl, Skye, contacts her, asking for Holt’s whereabouts. Julia meets Gabriel and finds a group of people known as \"The Sevens\", who are involved in an experiment involving the cursed video, watching and filming themselves, before passing the task to another person, called a “tail”.Julia recognizes Skye, who takes her to her apartment to have her watch the video, but Holt warns her not to. Julia locks herself in the bathroom as Skye is murdered by Samara, her tail having been late. Holt reveals that he has watched the tape as well and has 12 hours left. Unwilling to let Holt die, Julia watches his copy and when she picks up the phone, she experiences a vision of a door. The phone burns a mark on her hand. Gabriel notices Julia’s copy of the video cannot be copied and is larger than usual. He discovers extra images within the tape and Julia watches the new footage, which features a mysterious woman: she realizes they must cremate Samara\\'s physical remains.Gabriel sends them to the town Sacrament Valley, where Samara was given a burial after the residents of her island refused to accept the remains. He realizes the mark on Julia’s hand is Braille, translates it, and goes to warn them. Julia and Holt find an unmarked tomb, but when they break in, they find it empty. They are caught and taken to a blind man named Burke, who claims Samara’s body was entombed by the local priest but a flood came, leading the priest to bury her in a Potter\\'s field outside town.Heading for the field, Julia and Holt are stopped due to a car crash and learn Gabriel was involved. He tries to warn Julia of his discovery but is fatally electrocuted by a falling utility pole. After experiencing a vision of Samara’s birth mother, Evelyn, Julia and Holt return to town. Julia goes to the church and discovers a hidden chamber beneath the bell tower, finding evidence that Evelyn was imprisoned there whilst pregnant, held in captivity by the priest after being raped before she escaped eight months into the pregnancy.Julia visits Burke and explains her findings. He attacks her, revealing he was not only the priest but Samara’s biological father, and had blinded himself to escape the reach of his daughter’s powers. Julia pushes him down the stairs, temporarily incapacitating him. Holt rushes to Burke\\'s house, where he is knocked unconscious. Julia is drawn to a room in the house where she discovers Samara’s skeleton behind a wall. Burke appears and tries to choke her to death, informing her that she is the twelfth person Samara has sent to her remains; that destroying her remains would unleash an unspeakable evil upon the world, but a swarm of cicadas fly in, summoning Samara through Julia’s phone. Samara removes Burke’s blindness so she can kill him. Holt recovers and rushes to Julia\\'s aid. That night, he and Julia cremate Samara’s corpse and return home.While Julia is in the shower, Holt notices a voicemail from Gabriel, who warns him of the Braille. Holt translates it, discovering it means “rebirth”. In the bathroom, Julia peels away the skin where the mark was, revealing gray skin underneath. She begins to cough up black hair, from which a cicada is born. Holt unsuccessfully tries to disconnect the computer as Julia’s copy of the video is suddenly sent to everyone on her contact list and begins going viral. Julia gazes into the mirror: her reflection is that of Samara\\'s.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collect plot in this list\n",
    "plot = []\n",
    "\n",
    "# find the node with id of \"Plot\"\n",
    "mark = bs.find(id=\"Plot\")\n",
    "\n",
    "# walk through the siblings of the parent (H2) node \n",
    "# until we reach the next H2 node\n",
    "for elt in mark.parent.nextSiblingGenerator():\n",
    "    if elt.name == \"h2\":\n",
    "        break\n",
    "    if hasattr(elt, \"text\"):\n",
    "        plot.append(elt.text)\n",
    "\n",
    "# enjoy\n",
    "plot=\"\".join(plot)\n",
    "text = initial_paragraph + plot\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//upload.wikimedia.org/wikipedia/en/thumb/f/fe/102_dalmatians_poster.jpg/220px-102_dalmatians_poster.jpg\n"
     ]
    }
   ],
   "source": [
    "#https://en.wikipedia.org/wiki/101_Dalmatians_(1996_film)\n",
    "img=bs.findAll(\"img\",{\"class\":\"thumbborder\"})\n",
    "print(img[0]['src'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img=bs.findAll(\"\",{\"class\":\"image\"})\n",
    "for i in img:\n",
    "    img_URL = \"https://en.wikipedia.org\"+i['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://upload.wikimedia.org/wikipedia/en/thumb/3/30/Digimonthemovie.jpg/220px-Digimonthemovie.jpg\n"
     ]
    }
   ],
   "source": [
    "img=bs.findAll(\"img\",{\"class\":\"thumbborder\"})\n",
    "img_URL=\"https:\"+img[0]['src']\n",
    "print(img_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import os\n",
    "os.chdir(\"./images\")\n",
    "#ignore = urllib.request.urlretrieve(img_URL,os.path.basename(\"./images/\"+img_URL))\n",
    "ignore = urllib.request.urlretrieve(img_URL,os.path.basename(\"img_URL.jpg\"))\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(\"./images\")\n",
    "#ignore = urllib.request.urlretrieve(img_URL,os.path.basename(\"./images/\"+img_URL))\n",
    "ignore = urllib.request.urlretrieve(img_URL,os.path.basename(\"img_URL.jpg\"))\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Digimon: The Movie is a 2000 American film adaptation of the first three Japanese Digimon films, distributed by 20th Century Fox. The film used footage from the short films Digimon Adventure (1999) and Digimon Adventure: Our War Game! (2000), and the film Digimon Adventure 02: Digimon Hurricane Landing!! / Transcendent Evolution!! The Golden Digimentals (2000).Angela Anaconda[edit]A four-minute short film featuring characters from the Angela Anaconda series appeared before the film in the theatrical and home media releases. In this segment, Angela and her friends line up to watch Digimon: The Movie, but Nannette and her friends cut in line since they have passes. As Angela makes a mad dash to save seats for her friends, Mrs. Brinks (with help from Nannette) sits in front of her, blocking her view. Angela scornfully imagines herself Digivolving into Angelamon to defeat Mrs. Brinks and Nannette, removing all obstacles in enjoying her movie. However, everyone in the audience realizes they are in the wrong movie, so they quickly leave to go to the correct theater, leaving Mrs. Brinks and Nannette behind with the latter covered in food. Scenes from this short would later be reused in the episode \"Good Seats\"Eight Years Ago[edit]Main article: Digimon AdventureIn Highton View Terrace, before their adventure in the Digital World, siblings Tai and Kari Kamiya witness a Digi-Egg emerging from their computer. The egg soon hatches, revealing a Botamon. The Digimon rapidly digivolves into Koromon and then a very large Agumon, who unintentionally destroys a good part of the neighborhood, Kari states that this isn\\'t the same Agumon they become friends later with. A second Digi-Egg appears in the sky to reveal a Parrotmon. Agumon digivolves to Greymon, but brutally loses the battle. Tai wakes Greymon with Kari\\'s whistle, who defeats Parrotmon and disappears with him.Four Years Later[edit]Main article: Our War GameAbout six months after the DigiDestined departed from the Digital World, Izzy discovers a Digi-Egg on the internet that has been infected by a virus. He rushes over to Tai\\'s apartment to inform him about the newly hatched Digimon, Kuramon. Tai and Izzy monitor it and are astonished as Kuramon consumes large amounts of computer data to rapidly digivolve to Keramon. Gennai appears in a transmission from the Digital World, warning them about the dangers of his growth. He dispatches Agumon and Tentomon to stop the Digimon. Keramon digivolves into Infermon and easily defeats the Champion and Ultimate forms of Tentomon and Agumon. Izzy realizes that Keramon completely skipped over his Champion form and digivolved straight to his Ultimate level. Tai tries to alert the rest of the DigiDestined, but only succeeds in enlisting the help of Matt, T.K., Gabumon and Patamon. Agumon and Gabumon Warp Digivolve to WarGreymon and MetalGarurumon, prompting Infermon to Digivolve into Diaboromon. A massive amount of emails are sent to Tai and Izzy from people around the world who are watching the battle from their computers. This causes WarGreymon and MetalGarurumon to slow down and they are severely injured in the fight. Diaboromon begins to duplicate himself at an exponential rate and infects computers at the Pentagon, launching two nuclear intercontinental ballistic missiles: one headed for Colorado, the other for Tai and Izzy\\'s neighborhood in Odaiba, Tokyo. Refusing to lose hope, Tai and Matt\\'s bond with their Digimon allow them to become digital and enter the internet to comfort WarGreymon and MetalGarurumon. Tai and Matt remind them about all the people around the world watching them and sending emails with encouraging words. WarGreymon and MetalGarurumon are revived by the collective power of the millions of children around the world and DNA Digivolve to Omnimon. Omnimon easily defeats all of the Diaboromon copies, leaving only the original. With one minute left until the missile impact, Diaboromon is still too fast for them to hit. With seconds left on the clock, Izzy redirects the incoming emails to Diaboromon to slow him down. Omnimon destroys Diaboromon by stabbing him through the head just in time and the nukes are disabled just before detonation. However, the same virus that created Diaboromon tracks down Willis and corrupts Kokomon.Present Day[edit]Main article: Hurricane TouchdownWhile visiting Mimi in New York City, T.K. and Kari witness a battle between Willis, Terriermon, and Kokomon\\'s corrupted Champion form Wendigomon (still referred to as Kokomon). Wendigomon cryptically insists for Willis to \"go back\", to which he interprets as returning to Colorado. Thinking that he is to be in danger, Kari e-mails Davis Motomiya, Yolei Inoue, and Cody Hida for help in hopes of assembling in Colorado. However, T.K. and Kari\\'s train becomes derailed by Wendigomon on the way and they are unable to meet with the others. Meanwhile, after taking planes and taxis, Davis, Yolei, and Cody meet Willis in a truck. When Willis tries to get their group transportation to his house for some pizza, the ride leaves without him and Davis; however, Davis devises a plan to get themselves to Colorado faster with the help of Raidramon. At the rendez-vous point, Davis, Yolei, and Cody began to question Willis\\' knowledge about Wendigomon. Hesitantly, Willis reveals that he, as a child, tried to create a digi-egg after experiencing the joys of having his twin Digimon (Terriermon and Kokomon). However, this only resulted in Diaboromon\\'s creation. Willis assumes full responsibility for the situation. However, Davis and Terriermon convince him to let them help, as they are friends and are on the same team. At Willis\\'s home the next morning, Wendigomon expectedly reappears, but Digivolves to Antylamon and easily defeats the DigiDestined. Once digivolved into Cherubimon, he proceeds to eat their Digimon, but T.K. and Kari arrive at the nick of time to provide back-up with Angemon and Angewomon. Angry, Cherubimon de-Digivolves the Digimon then de-ages the Digidestined, revealing that he wanted Willis to \"go back\" in time to when the \"strange\" spirit first attacked him. To combat him, Angewomon and Angemon Digivolve to their Mega forms, Magnadramon and Seraphimon, to release two Golden Digi-Eggs for Willis and Davis. Veemon and Terriermon Golden Armor Digivolve to Magnamon and Rapidmon and allow themselves to be swallowed by Cherubimon. Inside, they see a manifestation of Wendigomon\\'s true self, who begs them to destroy the virus. After doing so, Cherubimon succumbs to his injuries and dies. After saying goodbye to his new friends, Willis and Terriermon walk back home to find Kokomon\\'s Digi-egg on the beach.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#url='https://en.wikipedia.org/wiki/Brother_(2000_film)'\n",
    "#url='https://en.wikipedia.org/wiki/The_Broken_Hearts_Club:_A_Romantic_Comedy'\n",
    "url='https://en.wikipedia.org/wiki/Digimon:_The_Movie'\n",
    "html = urlopen(url)\n",
    "bs = BeautifulSoup(html)\n",
    "#bs=bs.encode(\"utf-8\")\n",
    "\n",
    "# collect plot in this list\n",
    "plot = []\n",
    "\n",
    "# find the node with id of \"Plot\"\n",
    "mark = bs.find(id=\"Plot\")\n",
    "\n",
    "# walk through the siblings of the parent (H2) node \n",
    "# until we reach the next H2 node\n",
    "for elt in mark.parent.nextSiblingGenerator():\n",
    "    if elt.name == \"h2\":\n",
    "        break\n",
    "    if hasattr(elt, \"text\"):\n",
    "        plot.append(elt.text)\n",
    "\n",
    "# enjoy\n",
    "plot=\"\".join(plot)\n",
    "\n",
    "p = bs.find(\"p\")\n",
    "initial_paragraph = p.getText()\n",
    "\n",
    "text = initial_paragraph + plot\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Save_Text_File(text,text_file_name):\n",
    "    #try:\n",
    "    os.chdir(\"C:/Users/Sekhar/Documents/GitHub/WebAnalytics/Final_Project/data\")\n",
    "    #except:\n",
    "    #    return -1\n",
    "    \n",
    "    with open(text_file_name, 'w',encoding='utf-8') as f:\n",
    "        f.write(text)\n",
    "    \n",
    "    try:\n",
    "        os.chdir(\"..\")\n",
    "        return 0\n",
    "    except:\n",
    "        return -2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Save_Text_File(text,\"temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie</th>\n",
       "      <th>URL</th>\n",
       "      <th>Year</th>\n",
       "      <th>Director</th>\n",
       "      <th>Cast</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Movie_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Movie, URL, Year, Director, Cast, Genre, Movie_ID]\n",
       "Index: []"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"Movie\"]==\"Digimon\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie</th>\n",
       "      <th>URL</th>\n",
       "      <th>Year</th>\n",
       "      <th>Director</th>\n",
       "      <th>Cast</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Movie_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Bring It On</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Bring_It_On_(film)</td>\n",
       "      <td>2000</td>\n",
       "      <td>Peyton Reed</td>\n",
       "      <td>Kirsten Dunst, Eliza Dushku, Gabrielle Union, ...</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>The Broken Hearts Club: A Romantic Comedy</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Broken_Heart...</td>\n",
       "      <td>2000</td>\n",
       "      <td>Greg Berlanti</td>\n",
       "      <td>Ben Weber, Timothy Olyphant, Zach Braff</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Brother</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Brother_(2000_film)</td>\n",
       "      <td>2000</td>\n",
       "      <td>Takeshi Kitano</td>\n",
       "      <td>Takeshi Kitano, Omar Epps</td>\n",
       "      <td>Crime drama</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Cast Away</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Cast_Away</td>\n",
       "      <td>2000</td>\n",
       "      <td>Robert Zemeckis</td>\n",
       "      <td>Tom Hanks, Helen Hunt</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Cecil B. Demented</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Cecil_B._Demented</td>\n",
       "      <td>2000</td>\n",
       "      <td>John Waters</td>\n",
       "      <td>Melanie Griffith, Stephen Dorff, Alicia Witt, ...</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>The Cell</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Cell</td>\n",
       "      <td>2000</td>\n",
       "      <td>Tarsem Singh</td>\n",
       "      <td>Jennifer Lopez, Vince Vaughn, Vincent D'Onofrio</td>\n",
       "      <td>Science fiction</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Center Stage</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Center_Stage_(20...</td>\n",
       "      <td>2000</td>\n",
       "      <td>Nicholas Hytner</td>\n",
       "      <td>Amanda Schull, Peter Gallagher, Ethan Stiefel</td>\n",
       "      <td>Musical</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Charlie's Angels</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Charlie%27s_Ange...</td>\n",
       "      <td>2000</td>\n",
       "      <td>McG</td>\n",
       "      <td>Drew Barrymore, Cameron Diaz, Lucy Liu, Bill M...</td>\n",
       "      <td>Action</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Cherry Falls</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Cherry_Falls</td>\n",
       "      <td>2000</td>\n",
       "      <td>Geoffrey Wright</td>\n",
       "      <td>Brittany Murphy, Michael Biehn, Jesse Bradford</td>\n",
       "      <td>Thriller</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Chinese Coffee</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Chinese_Coffee</td>\n",
       "      <td>2000</td>\n",
       "      <td>Al Pacino</td>\n",
       "      <td>Al Pacino, Jerry Orbach</td>\n",
       "      <td>Drama</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Chocolat</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Chocolat_(2000_f...</td>\n",
       "      <td>2000</td>\n",
       "      <td>Lasse Hallström</td>\n",
       "      <td>Juliette Binoche, Judi Dench, Alfred Molina, L...</td>\n",
       "      <td>Romance</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Chuck &amp; Buck</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Chuck_%26_Buck</td>\n",
       "      <td>2000</td>\n",
       "      <td>Miguel Arteta</td>\n",
       "      <td>Chris Weitz, Mike White, Maya Rudolph</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>The Contender</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Contender_(2...</td>\n",
       "      <td>2000</td>\n",
       "      <td>Rod Lurie</td>\n",
       "      <td>Joan Allen, Jeff Bridges, Gary Oldman, Christi...</td>\n",
       "      <td>Drama</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Coyote Ugly</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Coyote_Ugly_(film)</td>\n",
       "      <td>2000</td>\n",
       "      <td>David McNally</td>\n",
       "      <td>Piper Perabo, Adam Garcia, Tyra Banks, John Go...</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>The Crew</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Crew_(2000_f...</td>\n",
       "      <td>2000</td>\n",
       "      <td>Michael Dinner</td>\n",
       "      <td>Richard Dreyfuss, Burt Reynolds, Dan Hedaya</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>The Crossing</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Crossing_(20...</td>\n",
       "      <td>2000</td>\n",
       "      <td>Robert Harmon</td>\n",
       "      <td>Jeff Daniels, Roger Rees, Sebastian Roché, Ste...</td>\n",
       "      <td>Historical Drama</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Cruel Intentions 2</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Cruel_Intentions_2</td>\n",
       "      <td>2000</td>\n",
       "      <td>Roger Kumble</td>\n",
       "      <td>Robin Dunne, Sarah Thompson, Keri Lynn Pratt</td>\n",
       "      <td>Comedy, drama</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Digimon: The Movie</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Digimon:_The_Movie</td>\n",
       "      <td>2000</td>\n",
       "      <td>Mamoru Hosoda, Minoru Hosoda</td>\n",
       "      <td>Lara Jill Miller, Joshua Seth, Bob Glouberman</td>\n",
       "      <td>Animation, Adventure</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Dinosaur</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Dinosaur_(film)</td>\n",
       "      <td>2000</td>\n",
       "      <td>Eric Leighton, Ralph Zondag</td>\n",
       "      <td>D. B. Sweeney, Alfre Woodard, Ossie Davis</td>\n",
       "      <td>Animation</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Movie  \\\n",
       "32                                Bring It On   \n",
       "33  The Broken Hearts Club: A Romantic Comedy   \n",
       "34                                    Brother   \n",
       "35                                  Cast Away   \n",
       "36                          Cecil B. Demented   \n",
       "37                                   The Cell   \n",
       "38                               Center Stage   \n",
       "39                           Charlie's Angels   \n",
       "40                               Cherry Falls   \n",
       "41                             Chinese Coffee   \n",
       "42                                   Chocolat   \n",
       "43                               Chuck & Buck   \n",
       "44                              The Contender   \n",
       "45                                Coyote Ugly   \n",
       "46                                   The Crew   \n",
       "47                               The Crossing   \n",
       "48                         Cruel Intentions 2   \n",
       "49                         Digimon: The Movie   \n",
       "50                                   Dinosaur   \n",
       "\n",
       "                                                  URL  Year  \\\n",
       "32   https://en.wikipedia.org/wiki/Bring_It_On_(film)  2000   \n",
       "33  https://en.wikipedia.org/wiki/The_Broken_Heart...  2000   \n",
       "34  https://en.wikipedia.org/wiki/Brother_(2000_film)  2000   \n",
       "35            https://en.wikipedia.org/wiki/Cast_Away  2000   \n",
       "36    https://en.wikipedia.org/wiki/Cecil_B._Demented  2000   \n",
       "37             https://en.wikipedia.org/wiki/The_Cell  2000   \n",
       "38  https://en.wikipedia.org/wiki/Center_Stage_(20...  2000   \n",
       "39  https://en.wikipedia.org/wiki/Charlie%27s_Ange...  2000   \n",
       "40         https://en.wikipedia.org/wiki/Cherry_Falls  2000   \n",
       "41       https://en.wikipedia.org/wiki/Chinese_Coffee  2000   \n",
       "42  https://en.wikipedia.org/wiki/Chocolat_(2000_f...  2000   \n",
       "43       https://en.wikipedia.org/wiki/Chuck_%26_Buck  2000   \n",
       "44  https://en.wikipedia.org/wiki/The_Contender_(2...  2000   \n",
       "45   https://en.wikipedia.org/wiki/Coyote_Ugly_(film)  2000   \n",
       "46  https://en.wikipedia.org/wiki/The_Crew_(2000_f...  2000   \n",
       "47  https://en.wikipedia.org/wiki/The_Crossing_(20...  2000   \n",
       "48   https://en.wikipedia.org/wiki/Cruel_Intentions_2  2000   \n",
       "49   https://en.wikipedia.org/wiki/Digimon:_The_Movie  2000   \n",
       "50      https://en.wikipedia.org/wiki/Dinosaur_(film)  2000   \n",
       "\n",
       "                        Director  \\\n",
       "32                   Peyton Reed   \n",
       "33                 Greg Berlanti   \n",
       "34                Takeshi Kitano   \n",
       "35               Robert Zemeckis   \n",
       "36                   John Waters   \n",
       "37                  Tarsem Singh   \n",
       "38               Nicholas Hytner   \n",
       "39                           McG   \n",
       "40               Geoffrey Wright   \n",
       "41                     Al Pacino   \n",
       "42               Lasse Hallström   \n",
       "43                 Miguel Arteta   \n",
       "44                     Rod Lurie   \n",
       "45                 David McNally   \n",
       "46                Michael Dinner   \n",
       "47                 Robert Harmon   \n",
       "48                  Roger Kumble   \n",
       "49  Mamoru Hosoda, Minoru Hosoda   \n",
       "50   Eric Leighton, Ralph Zondag   \n",
       "\n",
       "                                                 Cast                 Genre  \\\n",
       "32  Kirsten Dunst, Eliza Dushku, Gabrielle Union, ...                Comedy   \n",
       "33            Ben Weber, Timothy Olyphant, Zach Braff                Comedy   \n",
       "34                          Takeshi Kitano, Omar Epps           Crime drama   \n",
       "35                              Tom Hanks, Helen Hunt             Adventure   \n",
       "36  Melanie Griffith, Stephen Dorff, Alicia Witt, ...                Comedy   \n",
       "37    Jennifer Lopez, Vince Vaughn, Vincent D'Onofrio       Science fiction   \n",
       "38      Amanda Schull, Peter Gallagher, Ethan Stiefel               Musical   \n",
       "39  Drew Barrymore, Cameron Diaz, Lucy Liu, Bill M...                Action   \n",
       "40     Brittany Murphy, Michael Biehn, Jesse Bradford              Thriller   \n",
       "41                            Al Pacino, Jerry Orbach                 Drama   \n",
       "42  Juliette Binoche, Judi Dench, Alfred Molina, L...               Romance   \n",
       "43              Chris Weitz, Mike White, Maya Rudolph                Comedy   \n",
       "44  Joan Allen, Jeff Bridges, Gary Oldman, Christi...                 Drama   \n",
       "45  Piper Perabo, Adam Garcia, Tyra Banks, John Go...                Comedy   \n",
       "46        Richard Dreyfuss, Burt Reynolds, Dan Hedaya                Comedy   \n",
       "47  Jeff Daniels, Roger Rees, Sebastian Roché, Ste...      Historical Drama   \n",
       "48       Robin Dunne, Sarah Thompson, Keri Lynn Pratt         Comedy, drama   \n",
       "49      Lara Jill Miller, Joshua Seth, Bob Glouberman  Animation, Adventure   \n",
       "50          D. B. Sweeney, Alfre Woodard, Ossie Davis             Animation   \n",
       "\n",
       "    Movie_ID  \n",
       "32        32  \n",
       "33        33  \n",
       "34        34  \n",
       "35        35  \n",
       "36        36  \n",
       "37        37  \n",
       "38        38  \n",
       "39        39  \n",
       "40        40  \n",
       "41        41  \n",
       "42        42  \n",
       "43        43  \n",
       "44        44  \n",
       "45        45  \n",
       "46        46  \n",
       "47        47  \n",
       "48        48  \n",
       "49        49  \n",
       "50        50  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[31:50,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
