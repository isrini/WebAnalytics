{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "In this final project of Web Analytics course, we worked on building a movie recommender system based on movie's text scraped from Wikipedia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Import all the required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "import time\n",
    "import pickle #To save the objects that were created using webscraping\n",
    "import pprint\n",
    "from lxml import html\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import HTML\n",
    "import urllib\n",
    "import os\n",
    "\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data collection\n",
    "\n",
    "We scraped the text related to movie's plot from Wikipedia using a Python based web robot. The design of this web robot is present at: \n",
    "\n",
    "\n",
    "The data collection is divided into 2 phases:\n",
    "\n",
    "1. In the first phase the web robot has successfully scraped the list of target movie URLs, by iteratively visiting theweb site  https://en.wikipedia.org/wiki/List_of_American_films_of_xxxx (where xxxx represent the year. For example, to obtain the list of american movies released in 2000, we have to visit the website https://en.wikipedia.org/wiki/List_of_American_films_of_2000). From each URL the web robot will get the list of movie names, movie's Wiki page, cast, director and genre details. We scraped the list of movies for the years 2000-2016. A total of 4045 movies list was obtained. \n",
    "\n",
    "2. In the secod phase the web robot has visited all the 4045 URLs, and has successfully downloaded the movies plots from wikipedia. The web robot has run for approximately 7 hours to download 4045 movies text (we purposefully used a delay of 3 seconds between every hit, so that we do not overwhlem the wikipedia server with constant hits). \n",
    "\n",
    "The output of phase-1 is a comma separated file, with the following details: \n",
    "\n",
    "**Movie** - Movie Name\n",
    "\n",
    "**URL** - Wikipedia web page for the movie\n",
    "\n",
    "**Year** - Year of release\n",
    "\n",
    "**Director** - Director of the movie\n",
    "\n",
    "**Cast** - Cast of the movie\n",
    "\n",
    "**Genre** - Movie's genre\n",
    "\n",
    "**Movie_ID** - Unique key to distinguish each movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie</th>\n",
       "      <th>URL</th>\n",
       "      <th>Year</th>\n",
       "      <th>Director</th>\n",
       "      <th>Cast</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Movie_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102 Dalmatians</td>\n",
       "      <td>https://en.wikipedia.org/wiki/102_Dalmatians</td>\n",
       "      <td>2000</td>\n",
       "      <td>Kevin Lima</td>\n",
       "      <td>Glenn Close, Gérard Depardieu, Alice Evans</td>\n",
       "      <td>Comedy, family</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28 Days</td>\n",
       "      <td>https://en.wikipedia.org/wiki/28_Days_(film)</td>\n",
       "      <td>2000</td>\n",
       "      <td>Betty Thomas</td>\n",
       "      <td>Sandra Bullock, Viggo Mortensen</td>\n",
       "      <td>Drama</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3 Strikes</td>\n",
       "      <td>https://en.wikipedia.org/wiki/3_Strikes_(film)</td>\n",
       "      <td>2000</td>\n",
       "      <td>DJ Pooh</td>\n",
       "      <td>Brian Hooks, N'Bushe Wright</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The 6th Day</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_6th_Day</td>\n",
       "      <td>2000</td>\n",
       "      <td>Roger Spottiswoode</td>\n",
       "      <td>Arnold Schwarzenegger, Robert Duvall</td>\n",
       "      <td>Science fiction</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Across the Line</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Across_the_Line_...</td>\n",
       "      <td>2000</td>\n",
       "      <td>Martin Spottl</td>\n",
       "      <td>Brad Johnson, Adrienne Barbeau, Brian Bloom</td>\n",
       "      <td>Thriller</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Movie                                                URL  Year  \\\n",
       "0    102 Dalmatians       https://en.wikipedia.org/wiki/102_Dalmatians  2000   \n",
       "1           28 Days       https://en.wikipedia.org/wiki/28_Days_(film)  2000   \n",
       "2         3 Strikes     https://en.wikipedia.org/wiki/3_Strikes_(film)  2000   \n",
       "3       The 6th Day          https://en.wikipedia.org/wiki/The_6th_Day  2000   \n",
       "4   Across the Line  https://en.wikipedia.org/wiki/Across_the_Line_...  2000   \n",
       "\n",
       "             Director                                         Cast  \\\n",
       "0          Kevin Lima   Glenn Close, Gérard Depardieu, Alice Evans   \n",
       "1        Betty Thomas              Sandra Bullock, Viggo Mortensen   \n",
       "2             DJ Pooh                  Brian Hooks, N'Bushe Wright   \n",
       "3  Roger Spottiswoode         Arnold Schwarzenegger, Robert Duvall   \n",
       "4       Martin Spottl  Brad Johnson, Adrienne Barbeau, Brian Bloom   \n",
       "\n",
       "             Genre  Movie_ID  \n",
       "0   Comedy, family         1  \n",
       "1            Drama         2  \n",
       "2           Comedy         3  \n",
       "3  Science fiction         4  \n",
       "4         Thriller         5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4045, 7)\n"
     ]
    }
   ],
   "source": [
    "URL = pd.read_csv(\"Movies_URL_Latest.csv\")\n",
    "#URL[URL[\"Movie_ID\"] == 899]\n",
    "display(URL.head())\n",
    "print(URL.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of phase-2 is 4045 text files and image files (Not all the movies and images were downloaded. But will be fixed later). The output of phase-2 (text files) is further processed (cleaned by removing unnecessary characters, stop words etc) to create a CSV file, with the following format.\n",
    "\n",
    "**Movie_ID** - Unique ID of the movie\n",
    "\n",
    "**Plot** - Plot of the movie\n",
    "\n",
    "The initial rows of this file is displayed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie_ID</th>\n",
       "      <th>Plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>102 dalmatians 2000 american family comedy fil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>american psycho 2000 american black comedy hor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>legacy 2000 american documentary film directed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>lemony snicket series unfortunate events 2004 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001</td>\n",
       "      <td>life death peter sellers 2004 british-american...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Movie_ID                                               Plot\n",
       "0         1  102 dalmatians 2000 american family comedy fil...\n",
       "1        10  american psycho 2000 american black comedy hor...\n",
       "2       100  legacy 2000 american documentary film directed...\n",
       "3      1000  lemony snicket series unfortunate events 2004 ...\n",
       "4      1001  life death peter sellers 2004 british-american..."
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"processed_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the recommender\n",
    "\n",
    "## Get the TFIDF scores\n",
    "\n",
    "Using the data frame, we have to get the TFIDF scores for all the words in each of the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4037, 54075)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df[\"Plot\"])\n",
    "print(tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the cosine similarity measure between each pair of movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cos_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "\n",
    "#Convert cos_sim (a numpy array) to a data frame with rows and columns as movie IDs\n",
    "cos_sim_df = pd.DataFrame(cos_sim,columns=df[\"Movie_ID\"].tolist(),index=df[\"Movie_ID\"].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting recommendations\n",
    "Assume that the user has liked the following movies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the mapping between available Movie plots and movie IDs\n",
    "Movie_Map=pd.merge(URL[[\"Movie\",\"Movie_ID\"]],df,how='inner',on=[\"Movie_ID\"])[[\"Movie\",\"Movie_ID\"]]\n",
    "\n",
    "def Get_Recommendations(Movie_ID,cos_sim_df):\n",
    "    recommended_idx=np.argpartition(np.array(cos_sim_df[Movie_ID].tolist()), -6)[-6:]\n",
    "    Recommended_Movie_IDs = cos_sim_df.columns[recommended_idx].tolist()\n",
    "    return Recommended_Movie_IDs\n",
    "\n",
    "def Get_Available_Images():\n",
    "    \n",
    "    image_files = os.listdir(\"./images\")\n",
    "    #Make sure that we are dealing with movie data files only\n",
    "    image_files = [i for i in image_files if re.search('[1-9]*\\.jpg',i)]\n",
    "    y = list()\n",
    "    for i in image_files:\n",
    "        y.append(int(i.split(\".\")[0]))\n",
    "    return y\n",
    "\n",
    "def Display_Recommendations(Recommended_Movies,Movie_Map,Source_Movie_ID):\n",
    "    Movie_Map[Movie_Map[\"Movie_ID\"].isin(Recommended_Movies)][\"Movie_ID\"].tolist()\n",
    "    Available_Images_List = Get_Available_Images()\n",
    "    Source_Movie_Name = Movie_Map[Movie_Map[\"Movie_ID\"] == Source_Movie_ID][\"Movie\"].tolist()[0]\n",
    "    print(\"Since the user liked {}:\".format(Source_Movie_Name))\n",
    "    \n",
    "    Recommended_Movies = list(set(Recommended_Movies) - set([Source_Movie_ID]))\n",
    "    if Source_Movie_ID in Available_Images_List:\n",
    "        #print(\"The user has liked {}\".format(Source_Movie_Name))\n",
    "        display(HTML(\"<table><tr><td><img src='./images/\"+str(Source_Movie_ID)+\".jpg'></td></tr></table>\" \\\n",
    "            ))        \n",
    "        \n",
    "    display_html = \"\"\n",
    "    for i in Recommended_Movies:\n",
    "        if i in Available_Images_List:\n",
    "            display_html = display_html + \"<td><img src='./images/\"+str(i)+\".jpg'></td>\"\n",
    "    print(\"The following movies are recommended:\")        \n",
    "    display(HTML(\"<table><tr><td>\"+display_html+\"</tr></table>\" \\\n",
    "            ))        \n",
    "    #return display_html            \n",
    "    #Get available images for movies:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstration of the recommendations\n",
    "We will get recommended movies given that the user has liked some movies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Since the user liked  102 Dalmatians:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img src='./images/1.jpg'></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following movies are recommended:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><td><img src='./images/2080.jpg'></td><td><img src='./images/659.jpg'></td><td><img src='./images/3564.jpg'></td><td><img src='./images/2614.jpg'></td><td><img src='./images/1799.jpg'></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get recommendations for the Movie_IDs: [1, 73, 3316, 3883]\n",
    "Recommended_Movies = Get_Recommendations(1,cos_sim_df)\n",
    "Display_Recommendations(Recommended_Movies,Movie_Map,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Since the user liked Gladiator:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img src='./images/73.jpg'></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following movies are recommended:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><td><img src='./images/2176.jpg'></td><td><img src='./images/3295.jpg'></td><td><img src='./images/2675.jpg'></td><td><img src='./images/2782.jpg'></td><td><img src='./images/2759.jpg'></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "Recommended_Movies = Get_Recommendations(73,cos_sim_df)\n",
    "Display_Recommendations(Recommended_Movies,Movie_Map,73)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Since the user liked London Has Fallen:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img src='./images/3934.jpg'></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following movies are recommended:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><td><img src='./images/1081.jpg'></td><td><img src='./images/3446.jpg'></td><td><img src='./images/771.jpg'></td><td><img src='./images/644.jpg'></td><td><img src='./images/1163.jpg'></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Recommended_Movies = Get_Recommendations(3934,cos_sim_df)\n",
    "Display_Recommendations(Recommended_Movies,Movie_Map,3934)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Since the user liked Minions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img src='./images/3883.jpg'></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following movies are recommended:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><td><img src='./images/360.jpg'></td><td><img src='./images/851.jpg'></td><td><img src='./images/428.jpg'></td><td><img src='./images/2269.jpg'></td><td><img src='./images/2614.jpg'></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Recommended_Movies = Get_Recommendations(3883,cos_sim_df)\n",
    "Display_Recommendations(Recommended_Movies,Movie_Map,3883)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosine similarity is a numpy array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.31096471e-02,   1.00000000e+00,   9.44418644e-03, ...,\n",
       "          1.34289270e-02,   9.61086104e-04,   4.96355875e-03],\n",
       "       [  2.84413501e-03,   1.30861024e-02,   7.98737751e-03, ...,\n",
       "          1.48305863e-02,   7.58306966e-03,   1.05293617e-02],\n",
       "       [  9.75945776e-03,   1.13742963e-02,   9.06565598e-03, ...,\n",
       "          9.36789954e-03,   2.40102478e-03,   1.14813899e-02],\n",
       "       [  4.77905113e-03,   1.04962520e-02,   2.80845323e-03, ...,\n",
       "          1.78730739e-02,   2.41143992e-03,   5.36660507e-03],\n",
       "       [  2.02944376e-02,   1.54408038e-02,   8.46405079e-03, ...,\n",
       "          1.26664653e-02,   5.99270202e-04,   6.37538135e-03]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim[Interested_Movie_ID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given that the user liked  102 Dalmatians, the following movies are recommended:\n",
      "[3162 2781    1 1438 3002]\n",
      "Given that the user liked Gladiator, the following movies are recommended:\n",
      "[2038 2824 1654   73 2283]\n",
      "Given that the user liked Frozen, the following movies are recommended:\n",
      "[ 995 2559 1618  610 2772]\n",
      "Given that the user liked Frozen, the following movies are recommended:\n",
      "[3512 1604 3232 3554 3316]\n",
      "Given that the user liked Minions, the following movies are recommended:\n",
      "[1123 3511 1320 3883  508]\n"
     ]
    }
   ],
   "source": [
    "def Get_Recommendations(cos_sim, id,n,URL):\n",
    "    '''\n",
    "    cos_sim is the cosine similarity between each pair of movies\n",
    "    id is the movie_id\n",
    "    n is the desired number of recommendations\n",
    "    '''\n",
    "    for i in id:\n",
    "        print(\"Given that the user liked {}, the following movies are recommended:\"\n",
    "              .format(list(URL[\"Movie\"][URL[\"Movie_ID\"] == i])[0]))\n",
    "        ind = np.argpartition(cos_sim[i], -n)[-n:]\n",
    "        print(ind)\n",
    "        #print(cos_sim[i][ind])\n",
    "    #y[ind]\n",
    "Get_Recommendations(cos_sim, Interested_Movie_ID,5,URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'strip'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-0592490adf18>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mURL\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mURL\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Movie\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Gladiator\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"102 Dalmatians\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\sekhar\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3081\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3083\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'strip'"
     ]
    }
   ],
   "source": [
    "for i in list(URL[\"Movie\"]) if i \n",
    "\n",
    "URL[URL[\"Movie\"].isin([\"Gladiator\",\"102 Dalmatians\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the recommender\n",
    "\n",
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the files data into a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Read_File(p):\n",
    "   with open(p, 'r',encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "    #Convert all the text to lower case\n",
    "    #\n",
    "    lowers = text.lower()\n",
    "    #remove the punctuation using the character deletion step of translate\n",
    "    no_punctuation = lowers.translate(string.punctuation)\n",
    "    tokens = nltk.word_tokenize(no_punctuation)\n",
    "    return tokens\n",
    "\n",
    "def Remove_Stop_Words(tokens):\n",
    "    filtered = [w for w in tokens if not w in stopwords.words('english')]\n",
    "    return filtered\n",
    "\n",
    "\n",
    "\n",
    "def Clean_Text(tokens):\n",
    "    text = \" \".join(tokens)\n",
    "    #Remove punctuation marks, text in [], (, ), :\n",
    "    filtered1 = re.sub('\\.|\\`|\\'|\\[.*\\]|\\(|\\)|,|:', \" \",text)\n",
    "    \n",
    "    #Remove any single characters\n",
    "    filtered1 = re.sub('(^| ).( |$)', \" \",filtered1)\n",
    "    #Remove any contiguous spaces    \n",
    "    filtered1 = re.sub(' +',\" \",filtered1)\n",
    "    \n",
    "    #Include only alpha numeric characters\n",
    "    filtered1=\" \".join([i for i in filtered1.split() if re.search('[0-9 a-z]*',i)])\n",
    "    return filtered1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 files\n",
      "Processed 200 files\n",
      "Processed 300 files\n",
      "Processed 400 files\n",
      "Processed 500 files\n",
      "Processed 600 files\n",
      "Processed 700 files\n",
      "Processed 800 files\n",
      "Processed 900 files\n",
      "Processed 1000 files\n",
      "Processed 1100 files\n",
      "Processed 1200 files\n",
      "Processed 1300 files\n",
      "Processed 1400 files\n",
      "Processed 1500 files\n",
      "Processed 1600 files\n",
      "Processed 1700 files\n",
      "Processed 1800 files\n",
      "Processed 1900 files\n",
      "Processed 2000 files\n",
      "Processed 2100 files\n",
      "Processed 2200 files\n",
      "Processed 2300 files\n",
      "Processed 2400 files\n",
      "Processed 2500 files\n",
      "Processed 2600 files\n",
      "Processed 2700 files\n",
      "Processed 2800 files\n",
      "Processed 2900 files\n",
      "Processed 3000 files\n",
      "Processed 3100 files\n",
      "Processed 3200 files\n",
      "Processed 3300 files\n",
      "Processed 3400 files\n",
      "Processed 3500 files\n",
      "Processed 3600 files\n",
      "Processed 3700 files\n",
      "Processed 3800 files\n",
      "Processed 3900 files\n",
      "Processed 4000 files\n"
     ]
    }
   ],
   "source": [
    "file_names = os.listdir(\"./data\")\n",
    "file_names = [i for i in file_names if re.search('[1-9]*\\.txt',i)]\n",
    "y = list()\n",
    "x = list()\n",
    "k = 0\n",
    "for i in file_names:\n",
    "    y.append(int(i.split(\".\")[0]))\n",
    "    #print(y)\n",
    "    tokens = Read_File(\"./data/\"+i)\n",
    "    tokens = Remove_Stop_Words(tokens)\n",
    "    cleaned_text = Clean_Text(tokens)\n",
    "    x.append(cleaned_text)\n",
    "    k = k+1\n",
    "    if(k%100 == 0):\n",
    "        print(\"Processed {} files\".format(k))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame(list(zip(y,x)),columns = [\"Movie_ID\",\"Plot\"])\n",
    "df.to_csv(\"processed_data.csv\",encoding='utf-8',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie_ID</th>\n",
       "      <th>Plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>102 dalmatians 2000 american family comedy fil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>american psycho 2000 american black comedy hor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>legacy 2000 american documentary film directed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>lemony snicket series unfortunate events 2004 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001</td>\n",
       "      <td>life death peter sellers 2004 british-american...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Movie_ID                                               Plot\n",
       "0         1  102 dalmatians 2000 american family comedy fil...\n",
       "1        10  american psycho 2000 american black comedy hor...\n",
       "2       100  legacy 2000 american documentary film directed...\n",
       "3      1000  lemony snicket series unfortunate events 2004 ...\n",
       "4      1001  life death peter sellers 2004 british-american..."
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"processed_data.csv\")\n",
    "#df.head()\n",
    "#X = df.pop(\"Plot\")\n",
    "#display(X.head())\n",
    "#y = df.pop(\"Movie_ID\")\n",
    "#display(y)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time using sklearn package is 1.7591631412506104 sec\n",
      "\n",
      "The TF-IDF matrix has 4037 rows and 54075 columns\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "count_vect = CountVectorizer()\n",
    "X_counts = count_vect.fit_transform(df[\"Plot\"])\n",
    "#print(X_counts)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_tfidf = tfidf_transformer.fit_transform(X_counts)\n",
    "end=time.time()\n",
    "print(\"Run time using sklearn package is {} sec\\n\".format(end-start))\n",
    "#print \"Some of the initial TFIDF rows:\\n\\n{}\".format(X_tfidf[0:2])\n",
    "print(\"The TF-IDF matrix has {} rows and {} columns\\n\".format(X_tfidf.shape[0],X_tfidf.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4037, 54075)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df[\"Plot\"])\n",
    "print(tfidf_matrix.shape)\n",
    "#(4, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1201    2080\n",
       "2846    3564\n",
       "3660     659\n",
       "0          1\n",
       "Name: Movie_ID, dtype: int64"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cos_sim = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix)\n",
    "#array([[ 1.        ,  0.36651513,  0.52305744,  0.13448867]])\n",
    "#sorted(cos_sim[0])[-5:]\n",
    "ind = np.argpartition(cos_sim[0], -4)[-4:]\n",
    "cos_sim[0][ind]\n",
    "y[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brother is a 2000 American-British-Japanese film starring, written, directed, and edited by Takeshi Kitano.[2]Yamamoto Takeshi Kitano is a brutal and experienced Yakuza enforcer whose boss was killed and whose clan was defeated in a criminal war with a rival family. Surviving clan members have few options: either to join the winners, reconciling with shame and distrust, or to die by committing seppuku. Yamamoto, however, decides to escape to Los Angeles along with his associate Kato (Susumu Terajima). There he finds his estranged half-brother Ken (Claude Maki), who runs a small-time drug business together with his local African-American friends. At the first meeting, Yamamoto badly hurts one of them, Denny (Omar Epps), for an attempt to fraud him. Later, Denny becomes one of the Yamamoto's closest friends and associates.Used to living in a clan and according to its laws, Yamamoto creates a hapless gang out of Ken's buddies. The new gang quickly and brutally attacks Mexican drug bosses and takes control of their territory in LA. They also form an alliance with Shirase (Masaya Kato), a criminal leader of Little Tokyo district, making their group even stronger. As time passes, Yamamoto and his new gang emerge as a formidable force, gradually expanding their turf to such an extent that they confront the powerful Italian Mafia. Now everybody respectfully addresses Yamamoto as Aniki (å…„è²´, elder brother). But soon Aniki suddenly loses any interest in their now successful but dangerous business, spending his time with a girlfriend or just sitting silently thinking about something. However, the Mafia ruthlessly strikes back, and soon Yamamoto and his gang are driven into a disastrous situation of no return as they are hunted down one by one.\n",
      "[(',', 21), ('.', 13), ('and', 11), ('a', 11), ('yamamoto', 8), ('to', 8), ('with', 6), ('his', 6), ('the', 6), ('of', 6)]\n",
      "brother is a 2000 american-british-japanese film starring , written , directed , and edited by takeshi kitano . [ 2 ] yamamoto takeshi kitano is a brutal and experienced yakuza enforcer whose boss was killed and whose clan was defeated in a criminal war with a rival family . surviving clan members have few options : either to join the winners , reconciling with shame and distrust , or to die by committing seppuku . yamamoto , however , decides to escape to los angeles along with his associate kato ( susumu terajima ) . there he finds his estranged half-brother ken ( claude maki ) , who runs a small-time drug business together with his local african-american friends . at the first meeting , yamamoto badly hurts one of them , denny ( omar epps ) , for an attempt to fraud him . later , denny becomes one of the yamamoto 's closest friends and associates.used to living in a clan and according to its laws , yamamoto creates a hapless gang out of ken 's buddies . the new gang quickly and brutally attacks mexican drug bosses and takes control of their territory in la . they also form an alliance with shirase ( masaya kato ) , a criminal leader of little tokyo district , making their group even stronger . as time passes , yamamoto and his new gang emerge as a formidable force , gradually expanding their turf to such an extent that they confront the powerful italian mafia . now everybody respectfully addresses yamamoto as aniki ( å…„è²´ , elder brother ) . but soon aniki suddenly loses any interest in their now successful but dangerous business , spending his time with a girlfriend or just sitting silently thinking about something . however , the mafia ruthlessly strikes back , and soon yamamoto and his gang are driven into a disastrous situation of no return as they are hunted down one by one .\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def get_tokens():\n",
    "   with open('./data/34.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "    print(text)\n",
    "    lowers = text.lower()\n",
    "    #remove the punctuation using the character deletion step of translate\n",
    "    no_punctuation = lowers.translate(string.punctuation)\n",
    "    tokens = nltk.word_tokenize(no_punctuation)\n",
    "    return tokens\n",
    "\n",
    "tokens = get_tokens()\n",
    "count = Counter(tokens)\n",
    "print(count.most_common(10))\n",
    "print(\" \".join(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brother is a 2000 American-British-Japanese film starring, written, directed, and edited by Takeshi Kitano.[2]Yamamoto Takeshi Kitano is a brutal and experienced Yakuza enforcer whose boss was killed and whose clan was defeated in a criminal war with a rival family. Surviving clan members have few options: either to join the winners, reconciling with shame and distrust, or to die by committing seppuku. Yamamoto, however, decides to escape to Los Angeles along with his associate Kato (Susumu Terajima). There he finds his estranged half-brother Ken (Claude Maki), who runs a small-time drug business together with his local African-American friends. At the first meeting, Yamamoto badly hurts one of them, Denny (Omar Epps), for an attempt to fraud him. Later, Denny becomes one of the Yamamoto's closest friends and associates.Used to living in a clan and according to its laws, Yamamoto creates a hapless gang out of Ken's buddies. The new gang quickly and brutally attacks Mexican drug bosses and takes control of their territory in LA. They also form an alliance with Shirase (Masaya Kato), a criminal leader of Little Tokyo district, making their group even stronger. As time passes, Yamamoto and his new gang emerge as a formidable force, gradually expanding their turf to such an extent that they confront the powerful Italian Mafia. Now everybody respectfully addresses Yamamoto as Aniki (å…„è²´, elder brother). But soon Aniki suddenly loses any interest in their now successful but dangerous business, spending his time with a girlfriend or just sitting silently thinking about something. However, the Mafia ruthlessly strikes back, and soon Yamamoto and his gang are driven into a disastrous situation of no return as they are hunted down one by one.\n",
      "[(',', 21), ('.', 13), ('yamamoto', 8), ('(', 5), (')', 5), ('one', 4), ('gang', 4), ('clan', 3), ('ken', 2), ('takeshi', 2), ('however', 2), ('new', 2), ('mafia', 2), ('kato', 2), ('kitano', 2), ('drug', 2), ('brother', 2), ('whose', 2), ('criminal', 2), ('soon', 2), (\"'s\", 2), ('time', 2), ('aniki', 2), ('business', 2), ('denny', 2), ('friends', 2), ('decides', 1), ('alliance', 1), ('even', 1), ('distrust', 1), ('suddenly', 1), ('group', 1), ('return', 1), ('first', 1), ('2000', 1), ('interest', 1), ('driven', 1), ('later', 1), ('making', 1), ('estranged', 1), ('written', 1), ('turf', 1), ('everybody', 1), ('hapless', 1), ('options', 1), ('successful', 1), ('american-british-japanese', 1), ('directed', 1), ('gradually', 1), ('enforcer', 1), ('masaya', 1), ('force', 1), ('members', 1), ('epps', 1), ('quickly', 1), ('join', 1), ('committing', 1), ('closest', 1), ('addresses', 1), ('half-brother', 1), ('edited', 1), ('badly', 1), ('defeated', 1), ('living', 1), ('takes', 1), ('form', 1), ('elder', 1), ('situation', 1), ('also', 1), ('brutal', 1), ('surviving', 1), ('claude', 1), ('film', 1), ('together', 1), ('loses', 1), ('passes', 1), ('creates', 1), ('control', 1), ('die', 1), ('italian', 1), ('hunted', 1), ('according', 1), ('ruthlessly', 1), ('[', 1), ('omar', 1), ('small-time', 1), ('angeles', 1), ('bosses', 1), ('local', 1), ('respectfully', 1), ('attacks', 1), ('å…„è²´', 1), ('war', 1), ('silently', 1), (']', 1), ('hurts', 1), ('either', 1), ('2', 1), ('thinking', 1), (':', 1)]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "tokens = get_tokens()\n",
    "filtered = [w for w in tokens if not w in stopwords.words('english')]\n",
    "count = Counter(filtered)\n",
    "print(count.most_common(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['brother',\n",
       " '2000',\n",
       " 'american-british-japanese',\n",
       " 'film',\n",
       " 'starring',\n",
       " ',',\n",
       " 'written',\n",
       " ',',\n",
       " 'directed',\n",
       " ',',\n",
       " 'edited',\n",
       " 'takeshi',\n",
       " 'kitano',\n",
       " '.',\n",
       " '[',\n",
       " '2',\n",
       " ']',\n",
       " 'yamamoto',\n",
       " 'takeshi',\n",
       " 'kitano',\n",
       " 'brutal',\n",
       " 'experienced',\n",
       " 'yakuza',\n",
       " 'enforcer',\n",
       " 'whose',\n",
       " 'boss',\n",
       " 'killed',\n",
       " 'whose',\n",
       " 'clan',\n",
       " 'defeated',\n",
       " 'criminal',\n",
       " 'war',\n",
       " 'rival',\n",
       " 'family',\n",
       " '.',\n",
       " 'surviving',\n",
       " 'clan',\n",
       " 'members',\n",
       " 'options',\n",
       " ':',\n",
       " 'either',\n",
       " 'join',\n",
       " 'winners',\n",
       " ',',\n",
       " 'reconciling',\n",
       " 'shame',\n",
       " 'distrust',\n",
       " ',',\n",
       " 'die',\n",
       " 'committing',\n",
       " 'seppuku',\n",
       " '.',\n",
       " 'yamamoto',\n",
       " ',',\n",
       " 'however',\n",
       " ',',\n",
       " 'decides',\n",
       " 'escape',\n",
       " 'los',\n",
       " 'angeles',\n",
       " 'along',\n",
       " 'associate',\n",
       " 'kato',\n",
       " '(',\n",
       " 'susumu',\n",
       " 'terajima',\n",
       " ')',\n",
       " '.',\n",
       " 'finds',\n",
       " 'estranged',\n",
       " 'half-brother',\n",
       " 'ken',\n",
       " '(',\n",
       " 'claude',\n",
       " 'maki',\n",
       " ')',\n",
       " ',',\n",
       " 'runs',\n",
       " 'small-time',\n",
       " 'drug',\n",
       " 'business',\n",
       " 'together',\n",
       " 'local',\n",
       " 'african-american',\n",
       " 'friends',\n",
       " '.',\n",
       " 'first',\n",
       " 'meeting',\n",
       " ',',\n",
       " 'yamamoto',\n",
       " 'badly',\n",
       " 'hurts',\n",
       " 'one',\n",
       " ',',\n",
       " 'denny',\n",
       " '(',\n",
       " 'omar',\n",
       " 'epps',\n",
       " ')',\n",
       " ',',\n",
       " 'attempt',\n",
       " 'fraud',\n",
       " '.',\n",
       " 'later',\n",
       " ',',\n",
       " 'denny',\n",
       " 'becomes',\n",
       " 'one',\n",
       " 'yamamoto',\n",
       " \"'s\",\n",
       " 'closest',\n",
       " 'friends',\n",
       " 'associates.used',\n",
       " 'living',\n",
       " 'clan',\n",
       " 'according',\n",
       " 'laws',\n",
       " ',',\n",
       " 'yamamoto',\n",
       " 'creates',\n",
       " 'hapless',\n",
       " 'gang',\n",
       " 'ken',\n",
       " \"'s\",\n",
       " 'buddies',\n",
       " '.',\n",
       " 'new',\n",
       " 'gang',\n",
       " 'quickly',\n",
       " 'brutally',\n",
       " 'attacks',\n",
       " 'mexican',\n",
       " 'drug',\n",
       " 'bosses',\n",
       " 'takes',\n",
       " 'control',\n",
       " 'territory',\n",
       " 'la',\n",
       " '.',\n",
       " 'also',\n",
       " 'form',\n",
       " 'alliance',\n",
       " 'shirase',\n",
       " '(',\n",
       " 'masaya',\n",
       " 'kato',\n",
       " ')',\n",
       " ',',\n",
       " 'criminal',\n",
       " 'leader',\n",
       " 'little',\n",
       " 'tokyo',\n",
       " 'district',\n",
       " ',',\n",
       " 'making',\n",
       " 'group',\n",
       " 'even',\n",
       " 'stronger',\n",
       " '.',\n",
       " 'time',\n",
       " 'passes',\n",
       " ',',\n",
       " 'yamamoto',\n",
       " 'new',\n",
       " 'gang',\n",
       " 'emerge',\n",
       " 'formidable',\n",
       " 'force',\n",
       " ',',\n",
       " 'gradually',\n",
       " 'expanding',\n",
       " 'turf',\n",
       " 'extent',\n",
       " 'confront',\n",
       " 'powerful',\n",
       " 'italian',\n",
       " 'mafia',\n",
       " '.',\n",
       " 'everybody',\n",
       " 'respectfully',\n",
       " 'addresses',\n",
       " 'yamamoto',\n",
       " 'aniki',\n",
       " '(',\n",
       " 'å…„è²´',\n",
       " ',',\n",
       " 'elder',\n",
       " 'brother',\n",
       " ')',\n",
       " '.',\n",
       " 'soon',\n",
       " 'aniki',\n",
       " 'suddenly',\n",
       " 'loses',\n",
       " 'interest',\n",
       " 'successful',\n",
       " 'dangerous',\n",
       " 'business',\n",
       " ',',\n",
       " 'spending',\n",
       " 'time',\n",
       " 'girlfriend',\n",
       " 'sitting',\n",
       " 'silently',\n",
       " 'thinking',\n",
       " 'something',\n",
       " '.',\n",
       " 'however',\n",
       " ',',\n",
       " 'mafia',\n",
       " 'ruthlessly',\n",
       " 'strikes',\n",
       " 'back',\n",
       " ',',\n",
       " 'soon',\n",
       " 'yamamoto',\n",
       " 'gang',\n",
       " 'driven',\n",
       " 'disastrous',\n",
       " 'situation',\n",
       " 'return',\n",
       " 'hunted',\n",
       " 'one',\n",
       " 'one',\n",
       " '.']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "#filtered1 = ['[37]']\n",
    "#[i for i in filtered1 if re.search('.*\\[.*\\].*', i)]\n",
    "[\"\" for i in filtered if re.search(' *\\'s.*', i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"brother 2000 american-british-japanese film starring , written , directed , edited takeshi kitano . [ 2 ] yamamoto takeshi kitano brutal experienced yakuza enforcer whose boss killed whose clan defeated criminal war rival family . surviving clan members options : either join winners , reconciling shame distrust , die committing seppuku . yamamoto , however , decides escape los angeles along associate kato ( susumu terajima ) . finds estranged half-brother ken ( claude maki ) , runs small-time drug business together local african-american friends . first meeting , yamamoto badly hurts one , denny ( omar epps ) , attempt fraud . later , denny becomes one yamamoto 's closest friends associates.used living clan according laws , yamamoto creates hapless gang ken 's buddies . new gang quickly brutally attacks mexican drug bosses takes control territory la . also form alliance shirase ( masaya kato ) , criminal leader little tokyo district , making group even stronger . time passes , yamamoto new gang emerge formidable force , gradually expanding turf extent confront powerful italian mafia . everybody respectfully addresses yamamoto aniki ( å…„è²´ , elder brother ) . soon aniki suddenly loses interest successful dangerous business , spending time girlfriend sitting silently thinking something . however , mafia ruthlessly strikes back , soon yamamoto gang driven disastrous situation return hunted one one .\""
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered=\" \".join(filtered)\n",
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brother 2000 american-british-japanese film starring written directed edited takeshi kitano yamamoto takeshi kitano brutal experienced yakuza enforcer whose boss killed whose clan defeated criminal war rival family surviving clan members options either join winners reconciling shame distrust die committing seppuku yamamoto however decides escape los angeles along associate kato susumu terajima finds estranged half-brother ken claude maki runs small-time drug business together local african-american friends first meeting yamamoto badly hurts one denny omar epps attempt fraud later denny becomes one yamamoto closest friends associates used living clan according laws yamamoto creates hapless gang ken buddies new gang quickly brutally attacks mexican drug bosses takes control territory la also form alliance shirase masaya kato criminal leader little tokyo district making group even stronger time passes yamamoto new gang emerge formidable force gradually expanding turf extent confront powerful italian mafia everybody respectfully addresses yamamoto aniki å…„è²´ elder brother soon aniki suddenly loses interest successful dangerous business spending time girlfriend sitting silently thinking something however mafia ruthlessly strikes back soon yamamoto gang driven disastrous situation return hunted one one\n"
     ]
    }
   ],
   "source": [
    "filtered1 = re.sub('\\.|\\`|\\'|\\[.*\\]|\\(|\\)|,|:', \" \",filtered)\n",
    "#print(filtered1)\n",
    "filtered1 = re.sub('(^| ).( |$)', \" \",filtered1)\n",
    "filtered1 = re.sub(' +',\" \",filtered1)\n",
    "\n",
    "\n",
    "filtered1=\" \".join([i for i in filtered1.split() if re.search('[0-9 a-z]*',i)])\n",
    "print(filtered1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102 dalmatians 2000 american family comedy film directed kevin lima live-action directorial debut produced edward  feldman walt disney pictures sequel 1996 film 101 dalmatians stars glenn close reprising role cruella de vil attempts steal puppies  grandest  fur coat yet close tim mcinnerny two actors first film return sequel however film nominated academy award best costume design lost gladiator   three years prison cruella de vil cured desire fur coats dr  pavlov released custody probation office provision forced pay remainder fortune eight million pounds dog shelters borough westminster repeat crime cruella therefore mends working relationship valet alonzo lock away fur coats cruella  probation officer chloe simon nevertheless suspects partly chloe owner now-adult dipstick one original 15 puppies previous film   dipstick  mate dottie recently given birth three puppies domino little dipper oddball lacks spots   mend reputation cruella buys second chance dog shelter owned kevin shepherd resolve financial insolvency verge eviction meanwhile dr  pavlov discovers therapy  subjects subjected loud noises revert original states conceals discovery big ben rings presence cruella reverts former personality enlists help french furrier jean-pierre lepelt steal 102 dalmatian puppies new fur coat kevin tells chloe cruella violates parole entire fortune go since dog shelter one borough westminster cruella kevin framed theft puppies invites chloe dinner lepelt steals dottie three puppies dipstick hurries back apartment hides lepelt  truck later captured train station chloe rushes home save pets arrives late joined kevin escaped prison help dogs talking parrot waddlesworth upon finding ticket orient express paris dropped lepelt kevin chloe attempt fail stop cruella lepelt oddball waddlesworth pursue enemies secretly paris kevin chloe save captive puppies seen locked cellar puppies flee cruella goes puppies alone alonzo scolded beyond patience enough abused defeats lepelt frees kevin chloe give chase wedding cake factory puppies kevin  dogs imprison cruella immense cake lepelt thereupon arrested kevin chloe personally awarded remnants cruella  fortune alonzo oddball  coat develops spots \n",
      "[('cruella', 12), ('puppies', 10), ('kevin', 10), ('chloe', 9), ('lepelt', 7), ('film', 5), ('fur', 4), ('alonzo', 3), ('fortune', 3), ('three', 3), ('dog', 3), ('dipstick', 3), ('coat', 3), ('oddball', 3), ('one', 2), ('save', 2), ('close', 2), ('sequel', 2), ('dr', 2), ('steal', 2), ('dottie', 2), ('vil', 2), ('westminster', 2), ('original', 2), ('coats', 2), ('de', 2), ('dalmatians', 2), ('waddlesworth', 2), ('probation', 2), ('dogs', 2), ('paris', 2), ('spots', 2), ('102', 2), ('borough', 2), ('cake', 2), ('shelter', 2), ('pavlov', 2), ('prison', 2), ('help', 2), ('since', 1), ('pets', 1), ('best', 1), ('pay', 1), ('award', 1), ('return', 1), ('101', 1), ('grandest', 1), ('attempt', 1), ('joined', 1), ('violates', 1), ('pursue', 1), ('reverts', 1), ('1996', 1), ('remainder', 1), ('mcinnerny', 1), ('directed', 1), ('design', 1), ('repeat', 1), ('apartment', 1), ('invites', 1), ('recently', 1), ('however', 1), ('lock', 1), ('abused', 1), ('eight', 1), ('therapy', 1), ('tim', 1), ('role', 1), ('personally', 1), ('working', 1), ('stop', 1), ('comedy', 1), ('therefore', 1), ('partly', 1), ('released', 1), ('disney', 1), ('attempts', 1), ('escaped', 1), ('framed', 1), ('home', 1), ('captured', 1), ('go', 1), ('back', 1), ('reprising', 1), ('enough', 1), ('dipper', 1), ('hides', 1), ('finding', 1), ('theft', 1), ('forced', 1), ('office', 1), ('defeats', 1), ('cured', 1), ('little', 1), ('debut', 1), ('now-adult', 1), ('later', 1), ('thereupon', 1), ('discovers', 1), ('eviction', 1)]\n"
     ]
    }
   ],
   "source": [
    "count = Counter(filtered1.split())\n",
    "print(filtered1)\n",
    "print(count.most_common(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
